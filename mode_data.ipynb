{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Truth_Seeker_Model_Dataset_With_TimeStamps.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'author', 'statement', 'target', 'BinaryNumTarget',\n",
      "       'manual_keywords', 'tweet', '5_label_majority_answer',\n",
      "       '3_label_majority_answer', 'timestamp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_function(text):\n",
    "    # Check if the value is a string\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text_function(text):\n",
    "#     # Check if the value is a string\n",
    "#     if isinstance(text, str):\n",
    "#         # Convert to lowercase\n",
    "#         text = text.lower()\n",
    "\n",
    "#         # Remove special characters, URLs, and mentions\n",
    "#         text = re.sub(r'http\\S+|www\\S+|@[^\\s]+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "#         # Remove punctuation\n",
    "#         text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "#         # Tokenize the text\n",
    "#         words = word_tokenize(text)\n",
    "\n",
    "#         # Remove stop words\n",
    "#         stop_words = set(stopwords.words('english'))\n",
    "#         words = [word for word in words if word not in stop_words]\n",
    "\n",
    "#         # Stemming\n",
    "#         ps = PorterStemmer()\n",
    "#         words = [ps.stem(word) for word in words]\n",
    "\n",
    "#         # Reassemble the cleaned text\n",
    "#         cleaned_text = ' '.join(words)\n",
    "\n",
    "#         return cleaned_text\n",
    "#     # else:\n",
    "#         return \"\"  # or handle non-string values as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_function(text):\n",
    "    # Check if the value is a string\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "\n",
    "        # Remove special characters, URLs, and mentions\n",
    "        text = re.sub(r'http\\S+|www\\S+|@[^\\s]+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # Tokenize the text\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        # Stemming\n",
    "        ps = PorterStemmer()\n",
    "        words = [ps.stem(word) for word in words]\n",
    "\n",
    "        # Reassemble the cleaned text\n",
    "        cleaned_text = ' '.join(words)\n",
    "\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        return str(text)  # Convert non-string values to string or handle them as needed\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['clean_statement'] = df['statement'].apply(clean_text_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariw\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     clean_statement  cluster\n",
      "0  end evict moratorium mean million american cou...        2\n",
      "1  end evict moratorium mean million american cou...        2\n",
      "2  end evict moratorium mean million american cou...        2\n",
      "3  end evict moratorium mean million american cou...        2\n",
      "4  end evict moratorium mean million american cou...        2\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['clean_statement'])\n",
    "\n",
    "# K-means clustering\n",
    "num_clusters = 3  # Adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "# Display the first few rows of the DataFrame with assigned clusters\n",
    "print(df[['clean_statement', 'cluster']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
